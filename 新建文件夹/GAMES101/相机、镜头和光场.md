# 相机、镜头和光场

> Imaging = Synthesis + Capture.

## 小孔成像

用一个带有小孔的板遮挡在墙体与物之间，墙体上就会形成物的倒立的实像，这样的一种现象叫小孔成像（Pinhole Image Formation）。小孔成像的特点是得到的成像没有景深效果。

除了小孔成像之外，我们还会使用透镜成像。之所以必须要使用小孔或者透镜是因为传感器上每个点需要记录对应方向光线的数据，如果不使用小孔或者透镜，那么到达传感器上的光线将来自各个方向，不能区分。

## 视场

摄像机的视场（Field of View，FOV）的大小和传感器的大小以及焦距（小孔成像中指的是传感器和小孔的距离）有关。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231658150-69b5c7d1-d326-49ce-ac8b-7285641e57fe.png" alt="Img" style="zoom:75%;" />
</center>

由图可知：
$$
\text{FOV} = 2 \arctan \left(\frac{h}{2f}\right)
$$
从上述公式可以看出：

- 传感器越大，视场越大；
- 焦距越短，视场越大。

由于一些历史原因，在实际应用中，我们会采用 $35\text{mm}$ 胶片（$36 \times 24\text{mm}$）对应的焦距来反映视场的大小。焦距越小，对应的视场越大；焦距越大，拍摄的距离越远。较小的传感器需要使用较短的焦距来保持一样的视场。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231658975-1eb3311a-ddac-4c9e-b540-7ab06c035f85.png" alt="Img" style="zoom:75%;" />
</center>

## 曝光

曝光（Exposure，H）可以表示为曝光时间 T 和 Irradiance E 的乘积：
$$
H = T \times E
$$
其中，曝光时间由快门控制，Irradiance 是单位时间传感器单位面积上接受的光的强度，由光圈和焦距控制。

### 曝光控制

曝光的控制由以下三个参数决定：

- 光圈大小（Aperture size）：光圈的大小由 f-stop 控制，光圈是一个类似于瞳孔的结构，记作 F / N，其中 N 是 f 数，计算公式是 $\frac{f}{D}$，也就是焦距除以光圈直径。光圈越大景深效果越明显。
- 快门速度（Shutter speed）：决定了传感器的感光时间；快门速度越慢，得到的图片会出现模糊，我们称作**运动模糊**（Motion Blur）。运动模糊会使图像变模糊，但是可以体现出运动速度快，符合人眼规律。对于某些包含快速旋转物体的图片，由于图像每一个部分都在不同时间拍摄，因此会出现卷帘快门（Rolling Shutter）的现象。
- ISO 感光度（ISO gain）：传感器值乘一个常数变换为数字图像值，是一种后期处理。在数字相机中，高 ISO 会增加噪声。ISO 是一种线性增长（ISO 200 增加亮度的一半就是 ISO 100）。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231671812-06e3d19d-09fc-4ac4-970f-ab7ff19a9e3b.png" alt="Img" style="zoom:75%;" />
</center>

光圈和快门速度都可以控制曝光，因此理论上在一定的组合方式下，能够得到相同的曝光结果。但是，由于光圈和快门速度所带来的副作用不同，因此不同组合产生的效果也会有一些不同。在下表中，光圈和快门速度的组合能够得到相同的曝光。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231672238-aedbbe15-ac1e-41f5-b2c9-72785837282f.png" alt="Img" style="zoom:75%;" />
</center>

## 薄透镜近似（Thin Lens Approximation）

真实的透镜都是由透镜组所组成的。真实的透镜并不是理想的，这是因为平行光经过真实透镜后不能聚焦在同一个点上。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231672675-b8b0d124-50a0-4d90-bff4-4d6c9aee4af9.png" alt="Img" style="zoom:75%;" />
</center>

理想的薄透镜满足以下三点：

- 所有经过透镜的平行光都会聚焦在它的焦点；
- 所有经过透镜的焦点的光都会变成平行光；
- 透镜的焦距可以任意的变换。

### 透镜方程

在薄透镜中，焦距 $f$，物距 $z_0$，像距 $z_i$ 满足：
$$
\frac{1}{f} = \frac{1}{z_0} + \frac{1}{z_i}
$$

这被称为**薄透镜方程**（The Thin Lens Equation）。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231672903-c3ed5271-bfd3-4dfd-9b6a-d8dfb00dc546.png" alt="Img" style="zoom:75%;" />
</center>

#### 薄透镜方程的证明

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231673590-bbfb3d53-0524-486b-a469-bf853dba2051.png" alt="Img" style="zoom:75%;" />
</center>

根据相似三角形的性质，我们可以从蓝色相似三角形组和红色相似三角形组可以得到：
$$
\begin{align*}
\frac{h_0}{z-f} &= \frac{h_i}{f} \\
\frac{h_0}{f} &= \frac{h_i}{z_i - f}
\end{align*}
$$
联立公式可以得到：
$$
\frac{z_o - f}{f} = \frac{f}{z_i - f}
$$
整理可得：
$$
\frac{1}{f} = \frac{1}{z_o} + \frac{1}{z_i}
$$

### 离焦模糊（Defocus Blur）

当我们的物体不在聚焦平面的时候，它的像对应在传感器平面上是一个光圈，这个光圈被称为**弥散圆**（Circle of Confusion，CoC），这就是**离焦模糊**（Defocus Blur）现象。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231674535-1416f49a-531a-4bbc-85db-73f194a1afa0.png" alt="Img" style="zoom:75%;" />
</center>

弥散圆的直径 $C$ 和透镜的直径 $A$ 满足：
$$
\frac{C}{A} = \frac{d'}{z_i} = \frac{\left|z_s - z_i\right|}{z_i}
$$
我们又知道，光圈的大小 f-stop 由焦距和光圈的直径有决定。因此，上式可以改写成：
$$
C = A  \frac{\left|z_s - z_i\right|}{z_i} = \frac{f}{N} \frac{\left|z_s - z_i\right|}{z_i}
$$
因此，光圈 f-stop 越大，拍出来的相片越清晰，对应光圈的直径越小。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231675921-4fc42586-8e33-4cd1-83f8-619bf13d3470.png" alt="Img" style="zoom:75%;" />
</center>

### 薄透镜下的光线追踪（Ray Tracing Ideal Thin Lenses）

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231676268-ed66e9ca-3a5b-45fd-a2b5-e1968c323de5.png" alt="Img" style="zoom:75%;" />
</center>

之前我们的路径追踪都是在小孔摄像机的假设下。现在我们使用薄透镜模型进行光线追踪。首先，我们需要定义：

- 传感器大小，透镜的焦距以及透镜的孔径大小；
- 确定成像平面的距离 $z_o$。那么我们可以推算出传感器平面的距离 $z_i$。

我们按照以下方法确定路径：

- 选定每一个传感器像素上的点 $x'$;
- 在透镜平面上随机采样点 $x''$;
- 光线经过透镜会打到成像平面上的 $x'''$ 点；
- 计算从 $x'''$ 到 $x''$ 的 radiance，就是对应的 $x'$ 的结果。

### 景深

我们认为，当一段深度的物体能够保证 CoC 是足够小的，那么这一段深度我们称作**景深**（Depth ofField）。在实际中我们认为 CoC 小于一个像素的大小都可以看作足够小。景深的计算如下所示：

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231677188-491ab800-13c1-4ef9-964d-b28f5368fd5c.png" alt="Img" style="zoom:75%;" />
</center>

根据离焦模糊公式和薄透镜方程有：
$$
\begin{align*}
\frac{d_N-d_S}{d_N} & =\frac{C}{A} \\
\frac{d_S-d_F}{d_F} & =\frac{C}{A} \\
N & =\frac{f}{A} \\
\frac{1}{D_F}+\frac{1}{d_F} & =\frac{1}{f} \\
\frac{1}{D_S}+\frac{1}{d_S} & =\frac{1}{f} \\
\frac{1}{D_N}+\frac{1}{d_N} & =\frac{1}{f}
\end{align*}
$$
因此：
$$
\begin{align*}
\mathrm{DOF} & =D_F-D_N \\
D_F & =\frac{D_S f^2}{f^2-N C\left(D_S-f\right)} \\
D_N & =\frac{D_S f^2}{f^2+N C\left(D_S-f\right)}
\end{align*}
$$

## 光场（Light Field / Lumigraph）

对于人眼来说，不关心光线究竟是从哪里来的，因此可以用一张图片来模拟一种光。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231678046-0fe98b34-50a7-4f9f-8146-47b5ae1ffcd5.png" alt="Img" style="zoom:75%;" />
</center>

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231678074-152214f3-3d37-46dd-b496-0adc5cb7f7a1.png" alt="Img" style="zoom:75%;" />
</center>

在这里介绍全光函数（The Plenoptic Function）：
$$
P\left(\theta, \phi, \lambda, t, V_X, V_Y, V_Z\right)
$$

- $\theta$、$\phi$ 表示来提交，通过这两个参数可以描述光线的强度（即灰度值）；
- $\lambda$ 表示不同的波长，可以描述颜色信息；
- $t$，时间维度，引入 $t$ 后图片就动起来了，这就是电影；
- $V_X$、$V_Y$、$V_Z$，位置坐标，引入$V_X$、$V_Y$、$V_Z$ 后可以表示全息投影。

通过全光函数，我们可以记录所有的信息。光场（Light Field / Lumigraph）可以看作全光函数的一部分信息。

首先，我们定义光线，我们忽略颜色和时间参数。光线可以由两种方式进行定义，第一种方式是使用 3 维的起点以及 2 维的方向定义光线：
$$
P\left(\theta, \phi, V_X, V_Y, V_Z\right)
$$
通过 5 个维度我们定义了一个光线。但是我们可以通过两个点定义一条光线，这样子我们只需要四个维度就可以表示一条光线（只要我们定义好两个平面，上面的点都是 2 维的，因此两个点只需要 4 个维度就可以了）。

对于任何一个物体，我们可以使用一个包围盒来描述在各个方向上看到的光线情况。我们不关心包围盒内的物体情况，我们在观察时只用查询对应光场函数就可以了。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231679656-2033b6ec-3f03-45ab-8fee-ce5d4359bccf.png" alt="Img" style="zoom:75%;" />
</center>

我们关注一个面上的光场情况。前文提到，我们可以使用两个点表示一条光线。因此对于光场，我们也可以使用两个平面表示一个光场。其中，远离物体的为 s-t 平面，靠近物体的为 u-v 平面。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231679960-6ec8e408-4a6b-4dc1-9fbd-43f3016e907e.png" alt="Img" style="zoom:75%;" />
</center>

如果我们固定某一个平面上面的点，我们可以观察在另一平面上不同点的分布：

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231680107-fff8418e-a8b4-4a84-ab44-5cda0c9573d0.png" alt="Img" style="zoom:75%;" />
</center>

- 当我们固定 u-v 平面上的点，每一个 s-t 平面都是一副完整的图像；
- 当我们固定 s-t 平面上的点，每一个 u-v 平面上的点都是同一个像素在不同方向上看到的结果。

根据这样的方式，我们可以造出光场照相机（Light Field Camera）。光场照相机是一系列镜头矩阵构成的照相机。

<center>
    <img src="https://user-images.githubusercontent.com/62458905/231680577-e8ad6228-075b-4fec-8a4c-27373462143c.png" alt="Img" style="zoom:75%;" />
</center>


